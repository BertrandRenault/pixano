{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline pre-annotation with Pixano\n",
    "\n",
    "## 1. Setting up\n",
    "\n",
    "### Load imports\n",
    "\n",
    "This notebook requires the models implemented in the complementary [pixano-inference](https://github.com/pixano/pixano-inference) module that will be released soon.\n",
    "\n",
    "You will be able to install it with the following command line:\n",
    "\n",
    "```shell\n",
    "pip install pixano-inference@git+https://github.com/pixano/pixano-inference\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from pixano_inference import online_models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download checkpoints\n",
    "- Segment Anything Model:\n",
    "    - `default` or `vit_h`: [ViT-H SAM model](https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth).\n",
    "    - `vit_l`: [ViT-L SAM model](https://dl.fbaipublicfiles.com/segment_anything/sam_vit_l_0b3195.pth).\n",
    "    - `vit_b`: [ViT-B SAM model](https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth).\n",
    "    \n",
    "## 2. Computing the embeddings\n",
    "\n",
    "### Select a model\n",
    "\n",
    "- Loading a model:\n",
    "    - Segment Anything Model\n",
    "        - `model = online_models.SAM(checkpoint_path=Path(\"sam_vit_b_01ec64.pth\"), size=\"b\")`\n",
    "        - `model = online_models.SAM(checkpoint_path=Path(\"sam_vit_h_4b8939.pth\"), size=\"h\")`\n",
    "- Loading previously computed embeddings with model ID:\n",
    "    - `model = online_models.SAM(checkpoint_path=Path(\"sam_vit_h_4b8939.pth\"), size=\"h\", id=\"230414_094523_SAM_ViT_H\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = online_models.SAM(\n",
    "    checkpoint_path=Path(\"sam_vit_b_01ec64.pth\"),\n",
    "    size=\"b\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a dataset\n",
    "\n",
    "We will soon provide a guide on how to convert your own dataset to parquet format for accessing it with Pixano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library_dir = Path(\"datasets/\")\n",
    "dataset_dir = library_dir / \"coco_instances\"\n",
    "\n",
    "views = [\"image\"]\n",
    "splits = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dir = model.process_dataset(\n",
    "    input_dir=dataset_dir,\n",
    "    views=views,\n",
    "    splits=splits,\n",
    "    batch_size=2,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exporting to ONNX\n",
    "\n",
    "Provide existing ONNX model path or leave empty to export model to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_onnx_model()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Annotating an image\n",
    "\n",
    "*Coming soon...*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "px-next-4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
